{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import style\n",
    "style.use('dark_background')\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Platform  Userscore                                            Comment\n",
      "0  Nintendo64   0.760493  Everything in OoT is so near at perfection, it...\n",
      "1  Nintendo64   0.760493  I won't bore you with what everyone is already...\n",
      "2  Nintendo64   0.760493  Anyone who gives the masterpiece below a 7 or ...\n",
      "3  Nintendo64   0.760493  I'm one of those people who think that this is...\n",
      "4  Nintendo64   0.760493   This game is the highest rated game on Metacr... count    2.839600e+05\n",
      "mean    -2.562318e-17\n",
      "std      1.000002e+00\n",
      "min     -2.432663e+00\n",
      "25%     -1.974537e-01\n",
      "50%      4.411776e-01\n",
      "75%      7.604933e-01\n",
      "max      7.604933e-01\n",
      "Name: Userscore, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#reads document and standardizes user scores\n",
    "\n",
    "df = pd.read_csv('gamereviews.csv')\n",
    "df = df.drop(df.columns[[0, 1, 5]], axis=1)\n",
    "df.dropna(inplace=True)\n",
    "df['Userscore'] = StandardScaler().fit_transform(df[['Userscore']])\n",
    "\n",
    "print(df.head(), df['Userscore'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Userscore</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>Everything in OoT is so near at perfection, it...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>I won't bore you with what everyone is already...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>Anyone who gives the masterpiece below a 7 or ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>I'm one of those people who think that this is...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>This game is the highest rated game on Metacr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Platform  Userscore                                            Comment  \\\n",
       "0  Nintendo64   0.760493  Everything in OoT is so near at perfection, it...   \n",
       "1  Nintendo64   0.760493  I won't bore you with what everyone is already...   \n",
       "2  Nintendo64   0.760493  Anyone who gives the masterpiece below a 7 or ...   \n",
       "3  Nintendo64   0.760493  I'm one of those people who think that this is...   \n",
       "4  Nintendo64   0.760493   This game is the highest rated game on Metacr...   \n",
       "\n",
       "   Polarity  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Positive  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converts scores to sentiment\n",
    "\n",
    "df['Polarity'] = df['Userscore'].apply(lambda x: 'Positive' if (x > .76) else('Neutral' if (x <= .76) and (x >= -.197)  else 'Negative'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: Userscore, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = df['Userscore'].apply(lambda x: 2 if (x > .76) else(1 if (x <= .76) and (x >= -.197)  else 0))\n",
    "n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       283960\n",
       "unique           3\n",
       "top       Positive\n",
       "freq        112522\n",
       "Name: Polarity, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Polarity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Polarity'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get rid of stopwords and all non-letter characters\n",
    "\n",
    "def get_text_processing(text):\n",
    "    stpword = stopwords.words('english')\n",
    "    no_punctuation = [char for char in text if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Userscore</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>everything oot near perfection really wonder g...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>wont bore everyone already saying amazing game...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>anyone gives masterpiece 7 8 either hate astou...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>im one people think greatest game time matter ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nintendo64</td>\n",
       "      <td>0.760493</td>\n",
       "      <td>game highest rated game metacritic good reason...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Platform  Userscore                                            Comment  \\\n",
       "0  Nintendo64   0.760493  everything oot near perfection really wonder g...   \n",
       "1  Nintendo64   0.760493  wont bore everyone already saying amazing game...   \n",
       "2  Nintendo64   0.760493  anyone gives masterpiece 7 8 either hate astou...   \n",
       "3  Nintendo64   0.760493  im one people think greatest game time matter ...   \n",
       "4  Nintendo64   0.760493  game highest rated game metacritic good reason...   \n",
       "\n",
       "   Polarity  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Positive  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applies function and also converts all letters to lowercase\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(get_text_processing)\n",
    "df['Comment'] = df['Comment'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create polarity variables\n",
    "\n",
    "p = df['Polarity']\n",
    "onehot = pd.get_dummies(p)\n",
    "df.drop(['Polarity', 'Platform', 'Userscore'], axis=1, inplace=True)\n",
    "df = pd.concat([df, onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>everything oot near perfection really wonder g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wont bore everyone already saying amazing game...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyone gives masterpiece 7 8 either hate astou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im one people think greatest game time matter ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>game highest rated game metacritic good reason...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283955</th>\n",
       "      <td>extremely similar eo4 obviously isnt bad thing...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283956</th>\n",
       "      <td>typical overrated atlus trash game liked since...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283957</th>\n",
       "      <td>find story mode annoying characters intrusive ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283958</th>\n",
       "      <td>pretty good certainly lacks visual audio polis...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283959</th>\n",
       "      <td>first game etrian series hard time got used ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283960 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Comment  Negative  Neutral  \\\n",
       "0       everything oot near perfection really wonder g...         0        0   \n",
       "1       wont bore everyone already saying amazing game...         0        0   \n",
       "2       anyone gives masterpiece 7 8 either hate astou...         0        0   \n",
       "3       im one people think greatest game time matter ...         0        0   \n",
       "4       game highest rated game metacritic good reason...         0        0   \n",
       "...                                                   ...       ...      ...   \n",
       "283955  extremely similar eo4 obviously isnt bad thing...         1        0   \n",
       "283956  typical overrated atlus trash game liked since...         1        0   \n",
       "283957  find story mode annoying characters intrusive ...         0        1   \n",
       "283958  pretty good certainly lacks visual audio polis...         0        1   \n",
       "283959  first game etrian series hard time got used ch...         0        1   \n",
       "\n",
       "        Positive  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "...          ...  \n",
       "283955         0  \n",
       "283956         0  \n",
       "283957         0  \n",
       "283958         0  \n",
       "283959         0  \n",
       "\n",
       "[283960 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         everything oot near perfection really wonder g...\n",
      "1         wont bore everyone already saying amazing game...\n",
      "2         anyone gives masterpiece 7 8 either hate astou...\n",
      "3         im one people think greatest game time matter ...\n",
      "4         game highest rated game metacritic good reason...\n",
      "                                ...                        \n",
      "283955    extremely similar eo4 obviously isnt bad thing...\n",
      "283956    typical overrated atlus trash game liked since...\n",
      "283957    find story mode annoying characters intrusive ...\n",
      "283958    pretty good certainly lacks visual audio polis...\n",
      "283959    first game etrian series hard time got used ch...\n",
      "Name: Comment, Length: 283960, dtype: object         Negative  Neutral  Positive\n",
      "0              0        0         1\n",
      "1              0        0         1\n",
      "2              0        0         1\n",
      "3              0        0         1\n",
      "4              0        0         1\n",
      "...          ...      ...       ...\n",
      "283955         1        0         0\n",
      "283956         1        0         0\n",
      "283957         0        1         0\n",
      "283958         0        1         0\n",
      "283959         0        1         0\n",
      "\n",
      "[283960 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df['Comment']\n",
    "y = df.drop('Comment', axis=1)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Comment\n",
      "0       everyth oot near perfect real wond gam hug fan...\n",
      "1       wont bor everyon already say amaz gam yo fent ...\n",
      "2       anyon giv masterpiec 7 8 eith hat astound zeld...\n",
      "3       im on peopl think greatest gam tim mat qual ga...\n",
      "4       gam highest rat gam metacrit good reason tak e...\n",
      "...                                                   ...\n",
      "283955  extrem simil eo4 obvy isnt bad thing id say we...\n",
      "283956  typ over atl trash gam lik sint oldtim hardc p...\n",
      "283957  find story mod annoy charact intrud story clas...\n",
      "283958  pretty good certain lack vis audio pol iv many...\n",
      "283959  first gam et sery hard tim got us check map du...\n",
      "\n",
      "[283960 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download()\n",
    "#from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(lancaster.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "XS = pd.DataFrame(X)\n",
    "for i in range(0, len(X)):\n",
    "    XS.loc[i] = stemSentence(X[i])\n",
    "    \n",
    "print(XS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimension reduction filtering by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283960, 1460)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(strip_accents = 'unicode', max_df = .995, min_df = .005)\n",
    "XX = vect.fit_transform(XS['Comment'])\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "XX = tfidf.fit_transform(XX)\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimension reduction by svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283960, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "u, s, v = svds(XX)\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283960, 42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, cluster\n",
    "\n",
    "agglo = cluster.FeatureAgglomeration(n_clusters = 42)\n",
    "agglo.fit(XX.toarray())\n",
    "XR = agglo.transform(XX.toarray())\n",
    "XR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtr, xte, ytr, yte = train_test_split(XX, p, test_size = 0.2, random_state = 42)\n",
    "xtru, xteu, ytru, yteu = train_test_split(u, p, test_size = 0.2, random_state = 42)\n",
    "xtrr, xter, ytrr, yter = train_test_split(XR, p, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN model run with both regular df and svd df\n",
    "\n",
    "cv infeasible due to compute resources needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pg = /{'n_neighbors':np.arange(1, 30)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(estimator = knn, param_grid = pg, cv = 5)\n",
    "knn_cv.fit(XX, p)\n",
    "\n",
    "print(\"Best Score:\" + str(knn_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(knn_cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn = KNeighborsClassifier(knn_cv.best_params_['n_neighbors'])\n",
    "knn.fit(xte, yte)\n",
    "ypr = knn.predict(xte)\n",
    "print(confusion_matrix(yte, ypr), classification_report(yte, ypr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1607  1376 14713]\n",
      " [ 1065  1576 14077]\n",
      " [ 1236  1532 19610]]               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.41      0.09      0.15     17696\n",
      "     Neutral       0.35      0.09      0.15     16718\n",
      "    Positive       0.41      0.88      0.55     22378\n",
      "\n",
      "    accuracy                           0.40     56792\n",
      "   macro avg       0.39      0.35      0.28     56792\n",
      "weighted avg       0.39      0.40      0.31     56792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(100)\n",
    "knn.fit(xtr, ytr)\n",
    "ypr = knn.predict(xte)\n",
    "print(confusion_matrix(yte, ypr), classification_report(yte, ypr))\n",
    "\n",
    "#accuracy of .41, not a good model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "pg = {'n_neighbors':np.arange(1, 100)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(estimator = knn, param_grid = pg, cv = 5)\n",
    "knn_cv.fit(u, p)\n",
    "\n",
    "print(\"Best Score:\" + str(knn_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(knn_cv.best_params_))\n",
    "\n",
    "knn = KNeighborsClassifier(knn_cv.best_params_['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11128  2807  3761]\n",
      " [ 5203  4932  6583]\n",
      " [ 4889  3101 14388]]               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.52      0.63      0.57     17696\n",
      "     Neutral       0.45      0.30      0.36     16718\n",
      "    Positive       0.58      0.64      0.61     22378\n",
      "\n",
      "    accuracy                           0.54     56792\n",
      "   macro avg       0.52      0.52      0.51     56792\n",
      "weighted avg       0.53      0.54      0.52     56792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(300)\n",
    "knn.fit(xtru, ytru)\n",
    "ypr = knn.predict(xteu)\n",
    "print(confusion_matrix(yteu, ypr), classification_report(yteu, ypr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "pg = {'n_neighbors':np.arange(1, 100)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(estimator = knn, param_grid = pg, cv = 5)\n",
    "knn_cv.fit(XR, p)\n",
    "\n",
    "print(\"Best Score:\" + str(knn_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(knn_cv.best_params_))\n",
    "\n",
    "knn = KNeighborsClassifier(knn_cv.best_params_['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14236  1134  2326]\n",
      " [ 8735  2797  5186]\n",
      " [ 8205  2131 12042]]               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.46      0.80      0.58     17696\n",
      "     Neutral       0.46      0.17      0.25     16718\n",
      "    Positive       0.62      0.54      0.57     22378\n",
      "\n",
      "    accuracy                           0.51     56792\n",
      "   macro avg       0.51      0.50      0.47     56792\n",
      "weighted avg       0.52      0.51      0.48     56792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(300)\n",
    "knn.fit(xtrr, ytrr)\n",
    "ypr = knn.predict(xter)\n",
    "print(confusion_matrix(yter, ypr), classification_report(yter, ypr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model not feasible due to compute resources needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pg = {'bootstrap':[True, False], \n",
    "      'max_depth':np.arange(2, 10), \n",
    "      'min_samples_leaf': np.arange(2, 5), \n",
    "      'min_samples_split': np.arange(2, 5)}\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest_cv= GridSearchCV(estimator = forest, param_grid = pg, cv = 5)\n",
    "forest_cv.fit(u, p)\n",
    "\n",
    "print(\"Best Score:\" + str(forest_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(forest_cv.best_params_))\n",
    "\n",
    "#.53 accuracy: not better than knn, takes 8 hrs to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forest = RandomForestClassifier(n_estimators = 1000, \n",
    "                                bootstrap = forest_cv.best_params_['bootstrap'], \n",
    "                                max_depth = forest_cv.best_params_['max_depth'], \n",
    "                                min_samples_leaf = forest_cv.best_params_['min_samples_leaf'], \n",
    "                                min_samples_split = forest_cv.best_params_['min_samples_split'])\n",
    "forest.fit(xte, yte)\n",
    "ypr = forest.predict(xte)\n",
    "print(confusion_matrix(y_true = yte, y_pred = ypr), classification_report(yte, ypr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes' model run with both regular df and svd df\n",
    "\n",
    "Naive Bayes' requires dense matrix thus the not reduced df won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pg = {}\n",
    "gnb = GaussianNB()\n",
    "gnb_cv= GridSearchCV(estimator = gnb, param_grid = pg, cv = 5)\n",
    "gnb_cv.fit(XX, p)\n",
    "\n",
    "print(\"Best Score:\" + str(gnb_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(gnb_cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(xte, yte)\n",
    "ypr = gnb.predict(xte)\n",
    "print(confusion_matrix(y_true = yte, y_pred = ypr), classification_report(yte, ypr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.48115579659106916\n",
      "Best Parameters: {}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pg = {}\n",
    "gnb = GaussianNB()\n",
    "gnb_cv= GridSearchCV(estimator = gnb, param_grid = pg, cv = 5)\n",
    "gnb_cv.fit(u, p)\n",
    "\n",
    "print(\"Best Score:\" + str(gnb_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(gnb_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14545  1695  1456]\n",
      " [ 9769  3777  3172]\n",
      " [ 9971  3147  9260]]               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.42      0.82      0.56     17696\n",
      "     Neutral       0.44      0.23      0.30     16718\n",
      "    Positive       0.67      0.41      0.51     22378\n",
      "\n",
      "    accuracy                           0.49     56792\n",
      "   macro avg       0.51      0.49      0.46     56792\n",
      "weighted avg       0.52      0.49      0.46     56792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(xtru, ytru)\n",
    "ypr = gnb.predict(xteu)\n",
    "print(confusion_matrix(y_true = yteu, y_pred = ypr), classification_report(yteu, ypr))\n",
    "\n",
    "#accuracy of .48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.4921080433863924\n",
      "Best Parameters: {}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pg = {}\n",
    "gnb = GaussianNB()\n",
    "gnb_cv= GridSearchCV(estimator = gnb, param_grid = pg, cv = 5)\n",
    "gnb_cv.fit(XR, p)\n",
    "\n",
    "print(\"Best Score:\" + str(gnb_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(gnb_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14101  2409  1186]\n",
      " [ 8444  4942  3332]\n",
      " [ 8292  4800  9286]]               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.46      0.80      0.58     17696\n",
      "     Neutral       0.41      0.30      0.34     16718\n",
      "    Positive       0.67      0.41      0.51     22378\n",
      "\n",
      "    accuracy                           0.50     56792\n",
      "   macro avg       0.51      0.50      0.48     56792\n",
      "weighted avg       0.53      0.50      0.48     56792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(xtrr, ytrr)\n",
    "ypr = gnb.predict(xter)\n",
    "print(confusion_matrix(y_true = yter, y_pred = ypr), classification_report(yter, ypr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes' model run with both regular df and svd df\n",
    "\n",
    "model not working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pg = {}\n",
    "mnb = MultinomialNB()\n",
    "mnb_cv= GridSearchCV(estimator = mnb, param_grid = pg, cv = 5)\n",
    "mnb_cv.fit(XX, p)\n",
    "\n",
    "print(\"Best Score:\" + str(gnb_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(gnb_cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(xte, yte)\n",
    "ypr = mnb.predict(xte)\n",
    "print(confusion_matrix(y_true = yte, y_pred = ypr), classification_report(yte, ypr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD model run with both regular df and svd df\n",
    "\n",
    "regular df not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.529888012396112\n",
      "Best Parameters: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pg = {}\n",
    "clf = make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5))\n",
    "clf_cv= GridSearchCV(estimator = clf, param_grid = pg, cv = 5)\n",
    "clf_cv.fit(u, p)\n",
    "\n",
    "print(\"Best Score:\" + str(clf_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(clf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11559  1868  4269]\n",
      " [ 5914  3675  7129]\n",
      " [ 5200  2250 14928]]               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.51      0.65      0.57     17696\n",
      "     Neutral       0.47      0.22      0.30     16718\n",
      "    Positive       0.57      0.67      0.61     22378\n",
      "\n",
      "    accuracy                           0.53     56792\n",
      "   macro avg       0.52      0.51      0.50     56792\n",
      "weighted avg       0.52      0.53      0.51     56792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), \n",
    "                    LinearSVC(random_state=0, tol=1e-5))\n",
    "clf.fit(xtru, ytru)\n",
    "ypr = clf.predict(xteu)\n",
    "print(confusion_matrix(y_true = yteu, y_pred = ypr), classification_report(yteu, ypr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.5428863220171855\n",
      "Best Parameters: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pg = {}\n",
    "clf = make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5))\n",
    "clf_cv= GridSearchCV(estimator = clf, param_grid = pg, cv = 5)\n",
    "clf_cv.fit(XR, p)\n",
    "\n",
    "print(\"Best Score:\" + str(clf_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(clf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gary/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12297  1855  3544]\n",
      " [ 5884  3561  7273]\n",
      " [ 5079  2193 15106]]               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.53      0.69      0.60     17696\n",
      "     Neutral       0.47      0.21      0.29     16718\n",
      "    Positive       0.58      0.68      0.63     22378\n",
      "\n",
      "    accuracy                           0.55     56792\n",
      "   macro avg       0.53      0.53      0.51     56792\n",
      "weighted avg       0.53      0.55      0.52     56792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), \n",
    "                    LinearSVC(random_state=0, tol=1e-5))\n",
    "clf.fit(xtrr, ytrr)\n",
    "ypr = clf.predict(xter)\n",
    "print(confusion_matrix(y_true = yter, y_pred = ypr), classification_report(yter, ypr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network produces results with high loss but relatively high accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7099/7099 [==============================] - 32s 4ms/step - loss: 0.7651 - accuracy: 0.6533\n",
      "Epoch 2/4\n",
      "7099/7099 [==============================] - 32s 5ms/step - loss: 0.6602 - accuracy: 0.7065\n",
      "Epoch 3/4\n",
      "7099/7099 [==============================] - 33s 5ms/step - loss: 0.5284 - accuracy: 0.7760\n",
      "Epoch 4/4\n",
      "7099/7099 [==============================] - 32s 5ms/step - loss: 0.3561 - accuracy: 0.8587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f009b4540d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrnn, xtenn, ytrnn, ytenn = train_test_split(XX.toarray(), n, test_size = 0.2, random_state = 42)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=512, activation=\"relu\"))\n",
    "model.add(Dense(units=256, activation=\"relu\"))\n",
    "model.add(Dense(units=128, activation=\"relu\"))\n",
    "model.add(Dense(units=8, activation=\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(xtrnn, ytrnn, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1775/1775 [==============================] - 4s 2ms/step - loss: 0.9437 - accuracy: 0.6614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9436876773834229, 0.6614311933517456)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vloss, vacc = model.evaluate(xtenn, ytenn)\n",
    "vloss, vacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
